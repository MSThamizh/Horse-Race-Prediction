{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL_zNiopPN66"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Datasets**"
      ],
      "metadata": {
        "id": "P0xA_kaLPVfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/Horse'"
      ],
      "metadata": {
        "id": "qo0cWscUPaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_horse_data(path):\n",
        "    all_race_data = []\n",
        "    all_horse_data = []\n",
        "\n",
        "    for year in range(1990, 2021):\n",
        "        race_file = os.path.join(path, f\"races_{year}.csv\")\n",
        "        horse_file = os.path.join(path, f\"horses_{year}.csv\")\n",
        "\n",
        "        if os.path.exists(race_file):\n",
        "            race_data = pd.read_csv(race_file)\n",
        "            all_race_data.append(race_data)\n",
        "\n",
        "        if os.path.exists(horse_file):\n",
        "            horse_data = pd.read_csv(horse_file)\n",
        "            all_horse_data.append(horse_data)\n",
        "\n",
        "    race_data = pd.concat(all_race_data, ignore_index=True)\n",
        "    horse_data = pd.concat(all_horse_data, ignore_index=True)\n",
        "\n",
        "    forward_data = pd.read_csv(os.path.join(path, \"forward.csv\"))\n",
        "\n",
        "    return race_data, horse_data, forward_data\n",
        "\n",
        "race_data, horse_data, forward_data = load_horse_data(path)"
      ],
      "metadata": {
        "id": "a5-GlMuePcxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge Dataset**"
      ],
      "metadata": {
        "id": "l6F0ywZ9Q-hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = pd.merge(race_data, horse_data, on=\"rid\", how=\"inner\")"
      ],
      "metadata": {
        "id": "k21p3cWWRCHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "wG7RxdaTRRmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Datatypes**"
      ],
      "metadata": {
        "id": "2X04bF3JRWdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.info()\n",
        "\n",
        "merged_data['time'] = pd.to_datetime(merged_data['time'], format='%H:%M', errors='coerce').dt.time\n",
        "merged_data['date'] = pd.to_datetime(merged_data['date'], format='%y/%m/%d', errors='coerce')\n",
        "\n",
        "def convert_distance_to_furlongs(distance_str):\n",
        "    if isinstance(distance_str, str):\n",
        "        pattern = r\"(\\d+|\\½)(m|f|½?)\"\n",
        "        parts = re.findall(pattern, distance_str)\n",
        "        total_furlongs = 0\n",
        "        for value, unit in parts:\n",
        "            if unit == 'm':  # Miles\n",
        "                total_furlongs += int(value) * 8\n",
        "            elif unit == 'f':  # Furlongs\n",
        "                # Check if value is '½', if so add 0.5, otherwise convert to int and add\n",
        "                total_furlongs += 0.5 if value == '½' else int(value)\n",
        "            elif value == '½':  # Fractional furlong\n",
        "                total_furlongs += 0.5\n",
        "        return total_furlongs\n",
        "    return distance_str  # Return unchanged if not a string\n",
        "\n",
        "merged_data['distance'] = merged_data['distance'].apply(convert_distance_to_furlongs)\n",
        "\n",
        "merged_data.info()"
      ],
      "metadata": {
        "id": "xFOMQEg6RK0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Null Values**"
      ],
      "metadata": {
        "id": "0tSLv9D6hhoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.isnull().sum()\n",
        "\n",
        "# Drop unwanted columns\n",
        "# Horse Weight in three diff formats (kg, st, lb)\n",
        "# Distance in two diff formats (m f, meter)\n",
        "columns_to_drop = ['weightLb', 'weightSt', 'father', 'mother', 'gfather', 'distance']\n",
        "merged_data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Drop columns with >80% missing values\n",
        "columns_to_drop = ['currency', 'overWeight', 'outHandicap', 'headGear','price']\n",
        "merged_data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Drop rows with <2% missing values\n",
        "merged_data = merged_data.dropna(subset=['date', 'title', 'trainerName', 'jockeyName', 'age', 'condition'])\n",
        "\n",
        "merged_data.isnull().sum()"
      ],
      "metadata": {
        "id": "iSGEGJ8RhlN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding Categorical Variables**"
      ],
      "metadata": {
        "id": "gdn6v4G8vbwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns for Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_columns = ['positionL', 'dist', 'rclass', 'ages', 'condition', 'countryCode', 'ncond']\n",
        "model = LabelEncoder()\n",
        "for col in label_columns:\n",
        "    # Convert the column to string type before encoding\n",
        "    merged_data[col] = merged_data[col].astype(str)\n",
        "    merged_data[col] = model.fit_transform(merged_data[col])\n",
        "\n",
        "# Columns for Frequency Encoding\n",
        "freq_columns = ['course', 'band', 'hurdles', 'time', 'title', 'prizes',\n",
        "                'horseName', 'trainerName', 'jockeyName']\n",
        "for col in freq_columns:\n",
        "    freq_map = merged_data[col].value_counts().to_dict()\n",
        "    merged_data[col] = merged_data[col].map(freq_map)\n",
        "\n",
        "merged_data.info()"
      ],
      "metadata": {
        "id": "GVQrgQGcvc72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "oLwKLSDy6ONN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Horse Name to Aggregate Historical Data\n",
        "historical_metrics = merged_data.groupby('horseName').agg(\n",
        "    total_races=('rid', 'count'),\n",
        "    total_wins=('res_win', 'sum'),\n",
        "    total_places=('res_place', 'sum'),\n",
        "    avg_position=('position', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "historical_metrics['win_rate'] = historical_metrics['total_wins'] / historical_metrics['total_races']\n",
        "historical_metrics['place_rate'] = historical_metrics['total_places'] / historical_metrics['total_races']\n",
        "\n",
        "merged_data = merged_data.merge(historical_metrics, on='horseName', how='inner')"
      ],
      "metadata": {
        "id": "JdkBBcFY6Pt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate for Trainer\n",
        "trainer_metrics = merged_data.groupby('trainerName').agg(\n",
        "    trainer_races=('rid', 'count'),\n",
        "    trainer_wins=('res_win', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "trainer_metrics['trainer_success_rate'] = trainer_metrics['trainer_wins'] / trainer_metrics['trainer_races']\n",
        "\n",
        "merged_data = merged_data.merge(trainer_metrics[['trainerName', 'trainer_success_rate']], on='trainerName', how='inner')"
      ],
      "metadata": {
        "id": "yJuYdhP_6l6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate for Jockey\n",
        "jockey_metrics = merged_data.groupby('jockeyName').agg(\n",
        "    jockey_races=('rid', 'count'),\n",
        "    jockey_wins=('res_win', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "jockey_metrics['jockey_success_rate'] = jockey_metrics['jockey_wins'] / jockey_metrics['jockey_races']\n",
        "\n",
        "merged_data = merged_data.merge(jockey_metrics[['jockeyName', 'jockey_success_rate']], on='jockeyName', how='inner')"
      ],
      "metadata": {
        "id": "xRfWVIZH60N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track-Specific Performance\n",
        "track_performance = merged_data.groupby(['horseName', 'course']).agg(\n",
        "    avg_position_on_track=('position', 'mean'),\n",
        "    win_rate_on_track=('res_win', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "merged_data = merged_data.merge(track_performance, on=['horseName', 'course'], how='inner')"
      ],
      "metadata": {
        "id": "d_ddWzJW65og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "jbqp9AoKSt8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descriptive Statistics**"
      ],
      "metadata": {
        "id": "Fb6lJQ4NSxLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = ['prize', 'metric', 'winningTime', 'age', 'saddle', 'decimalPrice', 'RPR', 'TR', 'OR', 'runners', 'margin', 'weight', 'total_races',\n",
        "                     'total_wins', 'total_places', 'avg_position', 'win_rate', 'place_rate', 'trainer_success_rate', 'jockey_success_rate',\n",
        "                     'avg_position_on_track', 'win_rate_on_track']\n",
        "merged_data[numerical_columns].describe().T"
      ],
      "metadata": {
        "id": "LvnpMJAZSz6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "4J82G8P2zmYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plots - Before Treatment\n",
        "print('Before Treatment:')\n",
        "def visualize_plots(df, columns):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    # Boxplot\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.boxplot(data=df, x=columns)\n",
        "    plt.title(f'Boxplot of {columns}')\n",
        "\n",
        "    # Distribution Plot\n",
        "    plt.subplot(1,3,2)\n",
        "    sns.histplot(data=df, x=columns, kde=True, bins=50)\n",
        "    plt.title(f'Distribution Plot of {columns}')\n",
        "\n",
        "    # Violin Plot\n",
        "    plt.subplot(1,3,3)\n",
        "    sns.violinplot(data=df, x=columns)\n",
        "    plt.title(f'Violin Plot of {columns}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for i in ['prize', 'metric', 'winningTime', 'age', 'saddle', 'decimalPrice', 'RPR', 'TR', 'OR', 'runners', 'margin', 'weight', 'total_races', 'total_wins',\n",
        "          'total_places', 'avg_position', 'win_rate', 'place_rate', 'trainer_success_rate', 'jockey_success_rate', 'avg_position_on_track',\n",
        "          'win_rate_on_track']:\n",
        "          visualize_plots(merged_data, i)\n",
        "\n",
        "\n",
        "# Skewness Handling\n",
        "merged_data['prize_log'] = np.log(merged_data['prize'])\n",
        "\n",
        "# Outliers Detection and Cap the Outliers\n",
        "def detect_outliers_iqr(df, columns):\n",
        "    Q1 = df[columns].quantile(0.25)\n",
        "    Q3 = df[columns].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[columns] < lower_bound) | (df[columns] > upper_bound)].index\n",
        "    print(f'{columns} outliers: {len(outliers)}')\n",
        "\n",
        "    df[columns] = np.where(df[columns] < lower_bound, lower_bound, df[columns])\n",
        "    df[columns] = np.where(df[columns] > upper_bound, upper_bound, df[columns])\n",
        "\n",
        "for i in ['prize', 'metric', 'winningTime', 'age', 'saddle', 'decimalPrice', 'RPR', 'TR', 'OR', 'runners', 'margin', 'weight', 'total_races', 'total_wins',\n",
        "          'total_places', 'avg_position', 'win_rate', 'place_rate', 'trainer_success_rate', 'jockey_success_rate', 'avg_position_on_track',\n",
        "          'win_rate_on_track']:\n",
        "          detect_outliers_iqr(merged_data, i)\n",
        "\n",
        "\n",
        "# Distribution plots - After Treatment\n",
        "print('After Treatment:')\n",
        "def visualize_plots(df, columns):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    # Boxplot\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.boxplot(data=df, x=columns)\n",
        "    plt.title(f'Boxplot of {columns}')\n",
        "\n",
        "    # Distribution Plot\n",
        "    plt.subplot(1,3,2)\n",
        "    sns.histplot(data=df, x=columns, kde=True, bins=50)\n",
        "    plt.title(f'Distribution Plot of {columns}')\n",
        "\n",
        "    # Violin Plot\n",
        "    plt.subplot(1,3,3)\n",
        "    sns.violinplot(data=df, x=columns)\n",
        "    plt.title(f'Violin Plot of {columns}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for i in ['prize', 'metric', 'winningTime', 'age', 'saddle', 'decimalPrice', 'RPR', 'TR', 'OR', 'runners', 'margin', 'weight', 'total_races', 'total_wins',\n",
        "          'total_places', 'avg_position', 'win_rate', 'place_rate', 'trainer_success_rate', 'jockey_success_rate', 'avg_position_on_track',\n",
        "          'win_rate_on_track']:\n",
        "          visualize_plots(merged_data, i)"
      ],
      "metadata": {
        "id": "nOV-FgGxzp__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Analysis**"
      ],
      "metadata": {
        "id": "0ZYXkabbiA06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corr_matrix = merged_data[['prize', 'metric', 'winningTime', 'age', 'saddle', 'decimalPrice', 'RPR', 'TR', 'OR',\n",
        "                     'runners', 'margin', 'weight', 'total_races', 'total_wins',\n",
        "                     'total_places', 'avg_position', 'win_rate', 'place_rate', 'trainer_success_rate',\n",
        "                     'jockey_success_rate', 'avg_position_on_track', 'win_rate_on_track']].corr()\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QNiKrHqdiDFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modeling Approach**"
      ],
      "metadata": {
        "id": "GJIoat8a3Xs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "7io-manpUjC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Preprocessed Dataset\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/My Drive/horse_race_prediction_data.csv')\n",
        "sample_df = df.sample(n=200000, random_state=42)"
      ],
      "metadata": {
        "id": "7qX2vW6BUk3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Unnecessary Columns\n",
        "drop_columns = ['rid', 'title', 'date', 'time', 'positionL', 'dist']\n",
        "sample_df = sample_df.drop(columns=drop_columns)"
      ],
      "metadata": {
        "id": "bdG16t9NUueF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sample_df.drop(columns=['res_win', 'res_place'])\n",
        "y = sample_df['res_win']"
      ],
      "metadata": {
        "id": "JlG6SbM_UwGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_new, y_new = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "oTBfAlZ6Uzpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "c3DKcnr2U1tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing Best Model - Balanced Data\n",
        "\n",
        "models = [LogisticRegression(),\n",
        "          DecisionTreeClassifier(),\n",
        "          RandomForestClassifier(),\n",
        "          XGBClassifier(),\n",
        "          ExtraTreesClassifier()]\n",
        "\n",
        "for model in models:\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "    train_pred = model.predict(X_train)\n",
        "    test_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"*********{type(model).__name__}*********\")\n",
        "    print(f\"Train Accuracy: {accuracy_score(y_train,train_pred)}\")\n",
        "    print(f\"Train Precision: {precision_score(y_train,train_pred)}\")\n",
        "    print(f\"Train Recall: {recall_score(y_train,train_pred)}\")\n",
        "    print(f\"Train F1: {f1_score(y_train,train_pred)}\")\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy_score(y_test,test_pred)}\")\n",
        "    print(f\"Test Precision: {precision_score(y_test,test_pred)}\")\n",
        "    print(f\"Test Recall: {recall_score(y_test,test_pred)}\")\n",
        "    print(f\"Test F1: {f1_score(y_test,test_pred)} \\n \\n\")"
      ],
      "metadata": {
        "id": "--ze8Cy8U4CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestRegressor -  Easier Interpretability\n",
        "\n",
        "# Finding best parameters\n",
        "model = RandomForestClassifier()\n",
        "params = {\n",
        "    'n_estimators':[100, 150, 200],\n",
        "    'max_features':['sqrt', 'log2', None],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "cv = GridSearchCV(model,params, n_jobs=-1, cv=5)\n",
        "cv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "IPamMqsiU6Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.best_params_"
      ],
      "metadata": {
        "id": "F9TtrgYxU9sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.best_score_"
      ],
      "metadata": {
        "id": "zhsw_MrtU-3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve and AUC score\n",
        "fpr, tpr, thresholds = roc_curve(y_test, test_pred)\n",
        "auc_score = roc_auc_score(y_test, test_pred)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random performance\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve- Test Data\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# ROC curve and AUC score - Train Data\n",
        "fpr, tpr, thresholds = roc_curve(y_train, train_pred)\n",
        "auc_score = roc_auc_score(y_train, train_pred)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random performance\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve - Train Data\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zLwsrsF-VAGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix - Train\n",
        "conf_matrix = confusion_matrix(y_train, train_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix - Test\n",
        "conf_matrix = confusion_matrix(y_test, test_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iUFnh2QXVDHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}